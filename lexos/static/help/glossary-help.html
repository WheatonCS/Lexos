<!-- Glossary -->
<h3 class="help-section-title">Glossary</h3>

<h3 class="help-section-paragraph">
    This page is intended to provide definitions for the terms used within the
    Lexos suite, as well as to disambiguate terms drawn from natural language,
    programming languages, and linguistic analysis. New entries are being added
    on an ongoing basis.
</h3>

<!-- Terms and Definitions -->
<h3 class="help-section-title">Terms</h3>

<ul class="help-section-list" style="list-style-type: none">

    <li><b>Agglomerative Hierarchical Clustering</b></li>
    <h3 class="help-section-paragraph">
        Agglomerative Hierarchical Clustering is a method of bottom-up analysis
        wherein each document is its own cluster, after which the clusters are
        merged to form one cluster for all documents.
    </h3>

    <li><b>Average Linkage</b></li>
    <h3 class="help-section-paragraph">
        Also called UPGMA, this linkage is an un-weighted hybrid of complete and single linkages.
    </h3>

    <li><b>Bray-Curtis Distance</b></li>
    <h3 class="help-section-paragraph">
        The Bray-Curtis dissimilarity is a standardized form of Manhattan distance.
        Not metric itself, it is instead the proportion of values not shared between
        points, or, equivalently, the sum of absolute differences over the sum
        of all instances. Points further from the origin have more impact on
        the percentage.
    </h3>

    <li><b>Canberra Distance</b></li>
    <h3 class="help-section-paragraph">
        Canberra distance is a weighted version of the Manhattan distance. Instead
        of the sum of differences, it measures the sum of the difference ratios.
        The weighting allows this metric to be very sensitive to differences
        between points near the origin.
    </h3>

    <li><b>Character</b></li>
    <h3 class="help-section-paragraph">
        A character is any individual symbol. The letters that make up the Roman
        alphabet are characters, as are non-alphabetic symbols such as the Hanzi
        used in Chinese writing. In Lexos, the term character generally refers
        to countable symbols.
    </h3>

    <li><b>Chebyshev Distance</b></li>
    <h3 class="help-section-paragraph">
        The Chebyshev distance ignores all but the greatest component difference
        between two vectors. It is similar to Euclidean and Manhattan distances,
        in that instead of infinite (continuous) or square-grid (orthogonal)
        movement, it allows 8 directions of freedom (orthogonal and diagonal).
        It is used reliably in very niche circumstances.
    </h3>

    <li><b>Complete Linkage</b></li>
    <h3 class="help-section-paragraph">
        Also called the ‘farthest neighbour’ algorithm, this linkage produces
        spherical clusters of similar diameter.
    </h3>

    <li><b>Correlation Distance</b></li>
    <h3 class="help-section-paragraph">
        Correlation distance is equivalent to Cosine distance after vectors have
        been shifted by their means. Correlation distance metrics perform well
        in very high dimensions with few null values.
    </h3>

    <li><b>Cosine Distance</b></li>
    <h3 class="help-section-paragraph">
        Cosine distance is the measure of the angle formed by two vectors from
        the origin; it only judges the orientation of points in space, not their
        magnitudes. This metric is related to Euclidean distance by factoring
        dot products. Cosine distance is best for working in very high dimensions,
        especially if there are many null values in the vectors.
    </h3>

    <li><b>Cutting</b></li>
    <h3 class="help-section-paragraph">
        The process of creating multiple documents/segments from a source file.
    </h3>

    <li><b>Dendrogram</b></li>
    <h3 class="help-section-paragraph">
        The dendrogram is a method of visualizing how closely related documents
        are via hierarchical clustering analysis. The name derives from ‘dendron’,
        Greek for ‘tree’, and dendrograms are indeed rooted trees (a type of
        mathematical object). Each document, or leaf, of the tree is connected
        to every other by a series of branches. The length of each branch is
        distance from the center of the leaves of that branch to the next closest
        branch. One popular use for dendrograms are so-called ‘trees of life’
        which show how various species, genera, families, etc. are related.
    </h3>

    <li><b>Distance Metric</b></li>
    <h3 class="help-section-paragraph">
        The Distance Metric is the method used to compare two documents. Document
        data is stored in vectors, where each index contains the number of times
        a specific term appears. For example, the sentence, “The buffalo from
        Buffalo who buffalo buffalo from Buffalo buffalo buffalo from Buffalo”
        would have the vector < The:1, buffalo:5, from:3, Buffalo:3, who:1 >.
        Comparing this again a ‘sentence’ with no terms is equivalent to finding t
        he distance between the vectors <0,0,0,0,0> and <1,5,3,3,1>. The way the
        comparison is measured (distance between two points, number of words
        different, etc.) is the distance metric.
    </h3>

    <li><b>Divisive Clustering</b></li>
    <h3 class="help-section-paragraph">
        This top-down clustering method assumes all documents are in one cluster,
        then uses an algorithm to divide them until each document is in its own
        cluster.
    </h3>

    <li><b>Euclidean Distance</b></li>
    <h3 class="help-section-paragraph">
        The Euclidean distance is the 'intuitive' way of measuring distance: the
        length of a straight line between two points. This metric is one of the
        most widely used due to its reliability and simplicity.
    </h3>

    <li><b>File</b></li>
    <h3 class="help-section-paragraph">
        File refers to items that can be manipulated through the file manager on
        a user’s computer i.e. windows explorer, archive manager, etc. File is
        only used in the Lexos suite when referring to functions that involve the
        user’s file system, such as uploading or downloading.
    </h3>

    <li><b><em>Hapax Legomena</em></b></li>
    <h3 class="help-section-paragraph">
        A term occurring only once in a document or corpus.
    </h3>

    <li><b>Hamming Distance</b></li>
    <h3 class="help-section-paragraph">
        Hamming distance is similar to Jaccard, but it also considers shared absences
        and it completely ignores abundance in lieu of existence. The primary
        function is to determine the number of differing null and valued components.
        This is the best test to determine similarity between vocabularies. In
        Lexos, the Hamming distance is treated as a proportion instead of a raw count.
    </h3>

    <li><b>Hierarchical Cluster Analysis</b></li>
    <h3 class="help-section-paragraph">
        Hierarchical Clustering is a method of bottom-up analysis wherein the
        distance between each pair of documents is calculated and stored in a
        matrix that is reduced by iterating a linkage algorithm. This reduction
        yields the branch heights and divisions which are represented by a dendrogram.
        This method of analysis produces consistent results.
    </h3>

    <li><b>Jaccard Distance</b></li>
    <h3 class="help-section-paragraph">
        Derived from Bray-Curtis, the Jaccard distance is the ratio of the size
        of symmetric differences to the size of the union for the vector components
        of the points. Unlike the Bray-Curtis dissimilarity, Jaccard is metric.
        The primary use of Jaccard distance is to measure the dimensions unique
        to a vector.
    </h3>

    <li><b>Keepwords</b></li>
    <h3 class="help-section-paragraph">
        Keepwords are the opposite of stopwords. When scrubbing with the keepwords
        option, all terms except keepwords will be deleted. See stopwords.
    </h3>

    <li><b>Lemma</b></li>
    <h3 class="help-section-paragraph">
        The dictionary headword form of a word. For instance, “cat” is the lemma
        for “cat”, “cats”, “cat’s”, and “cats’”. Lemmas are generally used to
        consolidate grammatical variations of the same word as a single term,
        but they may also be used for spelling variants.
    </h3>

    <li><b>Lexomics</b></li>
    <h3 class="help-section-paragraph">
        The term “lexomics” was originally used to describe the computer-assisted
        detection of “words” (short sequences of bases) in genomes,* but we have
        extended it to apply to literature, where lexomics is the analysis of
        the frequency, distribution, and arrangement of words in large-scale
        patterns. Using statistical methods and computer-based tools to analyze
        data retrieved from electronic corpora, lexomic analysis allows us to
        identify patterns of vocabulary use that are too subtle or diffuse to be
        perceived easily. We then use the results derived from statistical and
        computer-based analysis to augment traditional literary approaches
        including close reading, philological analysis, and source study. Lexomics
        thus combines information processing and analysis with methods developed
        by medievalists over the past two centuries. We can use traditional methods
        to identify problems that can be addressed in new ways by lexomics, and
        we also use the results of lexomic analysis to help us zero in on textual
        relationships or portions of texts that might not previously have
        received much attention.
    </h3>

    <li><b>Manhattan Distance</b></li>
    <h3 class="help-section-paragraph">
        The Manhattan, or Taxicab, distance is so named because, unlike Euclidean
        distance, which 'goes as the crow flies', length is defined as the shortest
        path between two points on a grid - thus, it is more comparable to a taxicab's
        route in Manhattan. This metric is equivalent to measuring the area between
        two distribution curves (cf. Riemann sums). Manhattan distance is well-suited
        for points with fewer dimensions.
    </h3>

    <li><b>Segment</b></li>
    <h3 class="help-section-paragraph">
        After cutting a text in Lexos, the separated pieces of the text are referred
        to as segments. However, segments are treated by Lexos as documents and
        they may be referred to as documents when the focus is not on their being
        a part of the entire text.
    </h3>

    <li><b>Sparse Matrix</b></li>
    <h3 class="help-section-paragraph">
        A sparse matrix is a matrix that contains many null values.
    </h3>

    <li><b>Squared Euclidean Distance</b></li>
    <h3 class="help-section-paragraph">
        The Squared Euclidean distance is, as the name suggests, the Euclidean
        distance multiplied by itself. This additional operation places progressively
        greater weight on points that are further apart, and is thus very useful
        for sets of points that are extremely close together. The Squared Euclidean
        distance is also called the 'quadrance' in geometry.
    </h3>

    <li><b>Standard Deviation</b></li>
    <h3 class="help-section-paragraph">
        The standard deviation is a measure of a dataset’s diversity.
    </h3>

    <li><b>Standardized Euclidean Distance</b></li>
    <h3 class="help-section-paragraph">
        The standardization of the Euclidean distance is in the term 1/si, the
        reciprocal of the standard deviation of the i th component of all vectors.
        This inclusion adjusts the weights so all components have a variance of
        1 and a norm of 0. It is most useful for controlling factors that affect
        data disproportionately to other factors. If si instead represented the
        average abundance proportion, this would be chi-squared distance.
    </h3>

    <li><b>Stopwords</b></li>
    <h3 class="help-section-paragraph">
        A stopword is a term that is deleted during scrubbing. The stopword feature
        can be used to remove names, common terms, etc. from active files. See keepwords.
    </h3>

    <li><b>Term</b></li>
    <h3 class="help-section-paragraph">
        A term is the unique form of a token. If a token “cat” occurs two times
        in a document, the term count for “cat” is 2. In computational linguistics,
        terms are sometimes called “types”, but we avoid this usage for consistency.
    </h3>

    <li><b>Text</b></li>
    <h3 class="help-section-paragraph">
        Text is a general term used to refer to the objects studied in lexomics,
        irrespective of the form. It thus may refer to either a file or documents,
        but it is typically used to refer to the whole work, rather than smaller segments.
    </h3>

    <li><b>Token</b></li>
    <h3 class="help-section-paragraph">
        A token is an individual string of characters that may occur any number
        of times in a document. Tokens can be characters, words, or n-grams
        (strings of one or more characters or words).
    </h3>

    <li><b>Tokenization</b></li>
    <h3 class="help-section-paragraph">
        The process of dividing a text into tokens.
    </h3>

    <li><b>Type</b></li>
    <h3 class="help-section-paragraph">
        See term.
    </h3>

    <li><b>Vocabulary Density</b></li>
    <h3 class="help-section-paragraph">
        The ratio of the number of distinct words in a text to the total number
        of words in that text. A lower vocabulary density indicates a simpler
        text, with many reused words, and a higher vocabulary density indicates
        a more complex text, with many distinct words.
    </h3>

    <li><b>Weighted Linkage</b></li>
    <h3 class="help-section-paragraph">
        Also called WPGMA, this linkage is a weighted hybrid of single and complete.
    </h3>

    <li><b>Word</b></li>
    <h3 class="help-section-paragraph">
        A word is, in many Western languages, a set of characters bounded by
        whitespace or punctuation marks, where whitespace refers to one or more
        spaces, tabs, or new-line inserts. However, to avoid ambiguity when dealing
        with many non-Western languages such as Chinese, where a single Hanzi
        character can refer to the equivalent of an entire Western word, term is
        used throughout throughout the Lexos interface and documentation in place
        of word. There are a few exceptions where “word” is used because it is
        part of an established phrase, it is less awkward, or because the context
        refers to the semantic category of words.
    </h3>

</ul>
