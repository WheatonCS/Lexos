<!-- The Dendrogram Tool -->

<h3 class="help-section-title">The Dendrogram Tool</h3>

<h3 class="help-section-paragraph">
    Hierarchical cluster analysis is a good first choice when asking new questions
    about texts. Our experience has shown that this approach is remarkably versatile
    (REF). Perhaps more than any one individual method, the results from our
    cluster analyses continue to generate new, interesting, and focused questions.
</h3>

<!-- Options -->
<h3 class="help-section-title">Options</h3>

<ul class="help-section-list" style="list-style-type: none">

    <li><b>Distance Metric</b></li>
    <h3 class="help-section-paragraph">
        One of the most important (and least well-documented) aspects of the
        hierarchical clustering method is the distance metric. Since we are
        representing texts as document vectors, it makes sense to define document
        similarity by comparing the vectors. One way to do this is to measure
        the distance between each pair of vectors. For example, if two vectors
        are visualized as lines in a triangle, the hypotenuse between these lines
        can be used as a measure of the distance between the two documents. This
        method of measuring how far apart two documents are is known as Euclidean
        distance. While Euclidean distance is the default used by Lexos, below are
        suggestions that are more specialized. To chose a different distance metric
        click the button to see all the options, and then click "Generate" to see
        your changes reflected in the graph.
    </h3>

    <h3 class="help-section-paragraph">
    <table>
        <tr>
            <th style="border-top: none; border-left: none"></th>
            <th>Small Number of terms per segment</th>
            <th>Large Number of terms per segment</th>
        </tr>

        <tr>
            <th>Small Vocabulary</th>
            <td>Bray-Curtis<br><br>Hamming<br><br>(e.g. character dialogue)</td>
            <td>Euclidean<br><br>Chebyshev<br><br>Standardized Euclidean<br><br>(e.g. chapters of books)</td>
        </tr>

        <tr>
            <th>Large Vocabulary</th>
            <td>Correlation<br><br>Jaccard<br><br>Squared Euclidean<br><br>(e.g. non-epic poetry)</td>
            <td>Cosine<br><br>Manhattan<br><br>Canberra<br><br>(e.g. comparing entire corpora)</td>
        </tr>
    </table>
    </h3>

    <li><b>Linkage Method</b></li>
    <h3 class="help-section-paragraph">
        At each stage of the clustering process, a choice must be made about
        whether two clusters should be joined (and recall that a single document
        itself forms a cluster at the lowest level of the hierarchy). "Average"
        is the default, but you may choose other linkage methods by clicking the button.

        <ul class="help-section-list">
            <li>Average: Average linkage is a compromise between single and complete
                linkage. It takes the average distance of all the points in each
                cluster and uses the shortest average distance for deciding which
                cluster should be joined to the current one. We have had good
                success with average linkage.</li>

            <li>Single: An intuitive means for doing this is to join the cluster
                containing a point (e.g. a term frequency) closest to the current
                cluster. This is known as single linkage, which joins clusters
                based on only a single point. Single linkage does not take into
                account the rest of the points in the cluster, and the resulting
                dendrograms tend to have spread out clusters. This process is
                called "chaining". </li>

            <li>Complete: Complete linkage uses the opposite approach. It takes
                the two points furthest apart between the current cluster and the
                others. The cluster with the shortest distance to the current
                cluster is joined to it. Complete linkage thus takes into account
                all the points on the vector that come before the one with the
                maximum distance. It tends to produce compact, evenly distributed
                clusters in the resulting dendrograms.</li>

            <li>Weighted: The weighted average linkage performs the average linkage
                calculation but weights the distances based on the number of terms
                in the cluster. It, therefore, may be a good option when there
                is significant variation in the size of the documents under
                examination.</li>

        </ul>
    </h3>
    <h3 class="help-section-paragraph">
        Which linkage criterion you choose depends greatly on the variability
        of your data and your expectations of its likely cluster structure. The
        fact that it is very difficult to predict this in advance may explain
        why the "compromise" of average linkage is the best default.
    </h3>

    <li><b>Orientation</b></li>
    <h3 class="help-section-paragraph">
        The default orientation for the dendrogram is left. Click this button
        to see the other orientation options. Click "Generate" to see your changes
        reflected in the graph.
    </h3>

    <li><b>Tokenize</b></li>
    <h3 class="help-section-paragraph">
        By default Lexos tokenizes by tokens, meaning it splits strings of text
        into tokens every time it encounters a space character. For Western languages,
        this means that each token generally corresponds to a word. To tokenize
        by multiple words, you can increase the n-gram size.
    </h3>
    <h3 class="help-section-paragraph">
        For example given the text: "the dog ran" tokenizing by 1-gram tokens
        would produce tokens "the", "dog", "ran". Tokenizing by 2-grams would
        count the instances of bi-grams or pairs of words, thus producing tokens
        "the dog", "dog ran", and so on.
    </h3>
    <h3 class="help-section-paragraph">
        If you wish to tokenize by characters, Lexos will treat every character
        (letters, whitespace, punctuation, etc.) as a separate token. Tokenizing
        by 2-gram characters would produce tokens "th","he","e ", and so on.
        Tokenizing by characters is best used for non-western languages that don't
        have whitespace between tokens such as classical Chinese.
    </h3>

    <li><b>Normalize</b></li>
    <h3 class="help-section-paragraph">
        The default "Normalize" setting is "Proportional" which displays the
        frequency of the occurrence of terms in your documents as a proportion
        of the entire text.
    </h3>
    <h3 class="help-section-paragraph">
        "Raw Counts" will display in the table the actual number of occurrences
        of each term in each document.
    </h3>
    <h3 class="help-section-paragraph">
        "TF-IDF" or Term Frequency-Inverse Document Frequency attempts to
        take into account difference in the lengths of your documents by
        calculating their TF-IDF. Lexos uses base<em>e</em> (natural log) as the
        default.
    </h3>

    <li><b>Cull</b></li>
    <h3 class="help-section-paragraph">
        "Culling" is a generic term we use for methods of decreasing the number
        of terms used to generate the DTM based on statistical criteria (as
        opposed to something like applying a stop-word list in Scrubber). Culling
        is optional to use in Lexos. Lexos offers two different methods:
    </h3>
    <h3 class="help-section-paragraph">
        "Use the top ___ words": This method takes a slice of the DTM
        containing only the top N most frequently occurring terms in the
        set of active documents. The default setting is 100, meaning
        Tokenizer will generate the DTM using only the top 100 most
        frequent terms.
    </h3>
    <h3 class="help-section-paragraph">
        "Must be in ___ documents": This method build the DTM using only
        terms that occur in at least N documents. The default setting is
        1. If you have 10 active documents and you want to generate the
        DTM using only terms that appear in all your active documents,
        set the value to 10. <em><b>Note:</b> You can quickly determine
        the number of active documents in your workspace as indicated by
        the counter in the bottom right corner.</em>
    </h3>


</ul>

<!-- Results -->
<h3 class="help-section-title">Results</h3>

<ul class="help-section-list" style="list-style-type: none">

    <li><b>Dendrogram</b></li>
    <h3 class="help-section-paragraph">
        A dendrogram is a visual representation of the clusters and in Lexos is
        built by agglomerative hierarchical clustering. This method of clustering
        begins with every document as its own cluster and then proceeds to assign
        these items to “super-clusters” based on the selected distance metric
        and linkage criteria (see <em><u>Options</u></em> above).
    </h3>
    <h3 class="help-section-paragraph">
        The clusters that result from hierarchical clustering are typically
        visualized with a two-dimensional tree diagram called a dendrogram. For
        more information about the construction and interpretation of dendrograms
        in this method, see the video below:
    </h3>


    <iframe width="378" height="212.625" src="https://www.youtube.com/embed/MX6AUX1b1w0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</ul>


<ul class="help-section-list" style="list-style-type: none">

    <li><b>Plotly Menu</b></li>

    <h3 class="help-section-paragraph">
        If you pan over the graph, you'll notice that a menu appears in the top
        right corner.
        <ul class="help-section-list">

            <li>Zoom: This option allows you to click and drag to zoom in to a
            specific part of the graph.</li>

            <li>Pan: This option will change the click and drag function to
            panning across the graph.</li>

            <li>Zoom in and Zoom out: These will automatically zoom to the center
            of the graph.</li>

            <li>Auto-scale and Reset Axis: These options will zoom all the way out
            with the axis reset to fit the window</li>

            <li>Toggle spike lines: This option allows you to hover your mouse
            over data points and see where they are aligned on the x-axis and
            y-axis</li>

            <li>Show closest data on hover: If you hover over a data point,
            this option will show you the value of the data point.</li>

            <li>Compare data on hover: If you hover over a data point, this
            option will show you the value of the data point and it's corresponding
            x-axis value.</li>

        </ul>

    </h3>

    <li><b>Download</b></li>
    <h3 class="help-section-paragraph">
        The Dendrogram is downloadable in either <code>.svg</code> or
        <code>.png</code> format. SVG images are very useful because they scale
        well in web browsers.
    </h3>

</ul>

<!-- Examples -->
<h3 class="help-section-title">Examples</h3>

<h3 class="help-section-paragraph">
    Visit our public repository on GitHub
    <a target="_blank" href="https://github.com/WheatonCS/Lexos/tree/master/test/test_suite/Dendrogram"><u>here</u></a>
    for a test suite of examples you can use to generate dendrogram results
    before testing your own documents.
</h3>
