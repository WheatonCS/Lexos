<!-- The Bootstrap Consensus Tree Tool -->
<h3 class="help-section-title">The Bootstrap Consensus Tree Tool</h3>

<h3 class="help-section-paragraph">
    Bootstrap Consensus Trees provide a measure of the stability of cluster analyses,
    as discussed by M. Eder,  "Computational stylistics and biblical translation:
    how reliable can a dendrogram be?" In T. Piotrowski and Ł. Grabowski, editors,
    <em>The Translator and the Computer</em>, pages 155–170. WSF Press, Wrocław,
    2012.
</h3>

<h3 class="help-section-paragraph">
    Bootstrap Consensus Trees are a type of hierarchical cluster analysis that
    takes into account the sensitivity of cluster assignments to changes in the
    data or the parameters used to perform the clustering. With the Lexos
    <a href="/dendrogram"><u>Dendrogram</u></a> tool, it is easy to observe different
    results when you scrub or cut your data differently, or when you choose a
    different distance metric or linkage method. This can lead to uncertainty
    about how much meaning to attribute to the results of an individual experiment.
    Bootstrap consensus trees attempt to ascertain the stability of individual
    cluster assignments by analyzing many different variations of cluster analysis
    and displaying a "consensus" dendrogram with the assignments that occur with
    the most consistency. This dendrogram then represents a reliable indicator
    of the clusters that are sufficiently marked to recur regardless of minor
    changes in the data or the clustering parameters. This reliability provides
    additional confidence that the cluster assignment is meaningful, rather than
    an artifact of the statistical procedure.
</h3>

<!-- Options -->
<h3 class="help-section-title">Options</h3>

<h3 class="help-section-paragraph">
    Make sure you click "Generate" to see your changes reflected in the graph
</h3>

<ul class="help-section-list" style="list-style-type: none">

    <li><b>Sample with and without Replacement</b></li>
    <h3 class="help-section-paragraph">
        In sampling without replacement, each data sample is removed from the
        original data set before the next iteration. If you wish to replace the
        data, select "with" replacement.
    </h3>

    <li><b>Distance Metric</b></li>
    <h3 class="help-section-paragraph">
        This is the method for calculating the distance between each pair of vectors.
        While Euclidean distance is the default used by Lexos, below are
        suggestions that are more specialized. To chose a different distance metric
        click the button to see all the options, and then click "Generate" to see
        your changes reflected in the graph.
    </h3>

    <h3 class="help-section-paragraph">
    <table>
        <tr>
            <td style="border-top: none; border-left: none"></td>
            <th>Small Number of terms per segment</th>
            <th>Large Number of terms per segment</th>
        </tr>

        <tr>
            <th>Small Vocabulary</th>
            <td>Bray-Curtis<br><br>Hamming<br><br>(e.g. character dialogue)</td>
            <td>Euclidean<br><br>Chebyshev<br><br>Standardized Euclidean<br><br>(e.g. chapters of books)</td>
        </tr>

        <tr>
            <th>Large Vocabulary</th>
            <td>Correlation<br><br>Jaccard<br><br>Squared Euclidean<br><br>(e.g. non-epic poetry)</td>
            <td>Cosine<br><br>Manhattan<br><br>Canberra<br><br>(e.g. comparing entire corpora)</td>
        </tr>
    </table>
    </h3>

    <li><b>Linkage Method</b></li>
    <h3 class="help-section-paragraph">
        At each stage of the clustering process, a choice must be made about
        whether two clusters should be joined (and recall that a single document
        itself forms a cluster at the lowest level of the hierarchy). "Average"
        is the default, but you may choose other linkage methods by clicking the button.
        <ul class="help-section-list">
            <li>Average: Average linkage is a compromise between single and complete
                linkage. It takes the average distance of all the points in each
                cluster and uses the shortest average distance for deciding which
                cluster should be joined to the current one. We have had good
                success with average linkage.</li>

            <li>Single: An intuitive means for doing this is to join the cluster
                containing a point (e.g. a term frequency) closest to the current
                cluster. This is known as single linkage, which joins clusters
                based on only a single point. Single linkage does not take into
                account the rest of the points in the cluster, and the resulting
                dendrograms tend to have spread out clusters. This process is
                called "chaining". </li>

            <li>Complete: Complete linkage uses the opposite approach. It takes
                the two points furthest apart between the current cluster and the
                others. The cluster with the shortest distance to the current
                cluster is joined to it. Complete linkage thus takes into account
                all the points on the vector that come before the one with the
                maximum distance. It tends to produce compact, evenly distributed
                clusters in the resulting dendrograms.</li>

            <li>Weighted: The weighted average linkage performs the average linkage
                calculation but weights the distances based on the number of terms
                in the cluster. It, therefore, may be a good option when there
                is significant variation in the size of the documents under
                examination.b</li>

        </ul>
    </h3>

    <li><b>Cutoff</b></li>
    <h3 class="help-section-paragraph">
        This is the majority rule consensus cutoff: The percentage of times a
        document must appear in a clade to be considered in the consensus calculation.
        The default is 50%.
    </h3>

    <li><b>Iterations</b></li>
    <h3 class="help-section-paragraph">
        This is the number of bootstrap iterations: The number of times you wish
        the algorithm to perform sampling and clustering before producing the
        consensus clusters. The default is 100 iterations.
    </h3>

    <li><b>Tokenize</b></li>
    <h3 class="help-section-paragraph">
        By default Lexos tokenizes by tokens, meaning it splits strings of text
        into tokens every time it encounters a space character. For Western languages,
        this means that each token generally corresponds to a word. To tokenize
        by multiple words, you can increase the n-gram size.
    </h3>
    <h3 class="help-section-paragraph">
        For example given the text: "the dog ran" tokenizing by 1-gram tokens
        would produce tokens "the", "dog", "ran". Tokenizing by 2-grams would
        count the instances of bi-grams or pairs of words, thus producing tokens
        "the dog", "dog ran", and so on.
    </h3>
    <h3 class="help-section-paragraph">
        If you wish to tokenize by characters, Lexos will treat every character
        (letters, whitespace, punctuation, etc.) as a separate token. Tokenizing
        by 2-gram characters would produce tokens "th","he","e ", and so on.
        Tokenizing by characters is best used for non-western languages that don't
        have whitespace between tokens such as classical Chinese.
    </h3>

    <li><b>Normalize</b></li>
    <h3 class="help-section-paragraph">
        The default "Normalize" setting is "Proportional" which displays the
        frequency of the occurrence of terms in your documents as a proportion
        of the entire text.
    </h3>
    <h3 class="help-section-paragraph">
        "Raw Counts" will display in the table the actual number of occurrences
        of each term in each document.
    </h3>
    <h3 class="help-section-paragraph">
        "TF-IDF" or Term Frequency-Inverse Document Frequency attempts to
        take into account difference in the lengths of your documents by
        calculating their TF-IDF. Lexos uses base<em>e</em> (natural log) as the
        default.
    </h3>

    <li><b>Cull</b></li>
    <h3 class="help-section-paragraph">
        "Culling" is a generic term we use for methods of decreasing the number
        of terms used to generate the DTM based on statistical criteria (as
        opposed to something like applying a stop-word list in Scrubber). Culling
        is optional to use in Lexos. Lexos offers two different methods:
    </h3>
    <h3 class="help-section-paragraph">
        "Use the top ___ words": This method takes a slice of the DTM
        containing only the top N most frequently occurring terms in the
        set of active documents. The default setting is 100, meaning
        Tokenizer will generate the DTM using only the top 100 most
        frequent terms.
    </h3>
    <h3 class="help-section-paragraph">
        "Must be in ___ documents": This method build the DTM using only
        terms that occur in at least N documents. The default setting is
        1. If you have 10 active documents and you want to generate the
        DTM using only terms that appear in all your active documents,
        set the value to 10. <em><b>Note:</b> You can quickly determine
        the number of active documents in your workspace as indicated by
        the counter in the bottom right corner.</em>
    </h3>

</ul>

<!-- Results -->
<h3 class="help-section-title">Results</h3>

<ul class="help-section-list" style="list-style-type: none">

    <li><b>Consensus Tree</b></li>
    <h3 class="help-section-paragraph">
        The Bootstrap Consensus Tool works by selecting random samples (portions)
        of your active documents and performing a hierarchical cluster analysis
        of them. The algorithm then performs another iteration with a different
        random sample and calculates the consensus. In each iteration, 80% of
        the tokens in your data are sampled. This procedure is repeated over
        many more iterations (you can designate how many), and a dendrogram showing t
        he consensus cluster analysis is the result. This dendrogram may be
        compared to the results experiments produced by the Lexos
        <a href="/dendrogram"><u>Dendrogram</u></a> tool
    </h3>

    <li><b>Download</b></li>
    <h3 class="help-section-paragraph">
        The Conesnsus Tree is downloadable in <code>.png</code> format.
    </h3>

</ul>

<!-- Examples -->
<h3 class="help-section-title">Examples</h3>

<h3 class="help-section-paragraph">
    Visit our public repository on GitHub
    <a target="_blank" href="https://github.com/WheatonCS/Lexos/tree/master/test/test_suite/ConsensusTree"><u>here</u></a>
    for a test suite of examples you can use to generate consensus tree results
    before testing your own documents.
</h3>
